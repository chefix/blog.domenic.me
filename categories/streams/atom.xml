<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: streams | Hidden Variables]]></title>
  <link href="https://blog.domenic.me/categories/streams/atom.xml" rel="self"/>
  <link href="https://blog.domenic.me/"/>
  <updated>2015-03-16T19:56:47+09:00</updated>
  <id>https://blog.domenic.me/</id>
  <author>
    <name><![CDATA[Domenic Denicola]]></name>
    <email><![CDATA[d@domenic.me]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Reading from Sockets]]></title>
    <link href="https://blog.domenic.me/reading-from-sockets/"/>
    <updated>2015-03-16T09:00:00+09:00</updated>
    <id>https://blog.domenic.me/reading-from-sockets</id>
    <content type="html"><![CDATA[<p><em>This post is part of a series on the byte sources underlying the readable streams in the Streams Standard. See <a href="/byte-sources-introduction/">the introductory post</a> for more background and links to the rest of the series.</em></p>

<p>At the simplest level, sockets can be treated much the same as files. You can get a file descriptor for the socket, and while there are a number APIs involved in setting it up to actually connect to a remote server, once you&rsquo;ve done that you can read from it using the same read(2) interface as <a href="/reading-from-files/">we discussed for files</a>.</p>

<p>But! For sockets, there&rsquo;s an advanced technique available. Instead of using the straightforward-but-blocking read(2) call, we can fine-tune our syscall usage to give us our first taste of <strong>non-blocking I/O</strong>.  That is, there&rsquo;s a way to arrange it so that—without spinning up any threads—we can continue doing work while the OS gets our data ready for us.</p>

<h2 id="non-blocking-socket-i/o">Non-Blocking Socket I/O</h2>

<p>A quick aside. In higher-level languages, non-blocking <em>I/O</em> is often conflated with non-blocking <em>APIs</em>. These are actually distinct concepts, and for clarity we&rsquo;ll refer to the latter as &ldquo;asynchronous&rdquo; instead. So: I/O can be blocking or non-blocking; APIs can be synchronous or asynchronous. An asynchronous API in a higher-level language might be backed by non-blocking I/O syscalls, or it might be backed by blocking I/O syscalls in a threadpool (as we showed in the file case).</p>

<p>What&rsquo;s really interesting is what the APIs for non-blocking I/O look like in C. They&rsquo;re nothing like what you might expect from working in a higher-level language, where concepts like &ldquo;events&rdquo; or &ldquo;callbacks&rdquo; are present to do the heavy lifting. Instead, it works something like this:</p>

<ul>
<li>When creating the socket, you set it to non-blocking mode.</li>
<li>You go do some other work, and every once in a while, you come back and try to read some data from the socket.

<ul>
<li>If the OS has data ready for you, you get it instantly!</li>
<li>Otherwise, if there&rsquo;s no data ready, the OS returns a special error code, saying to try again later.</li>
<li>(Of course, there&rsquo;s always the possibility that something went wrong, and you&rsquo;ll get a non-special error code.)</li>
</ul></li>
</ul>

<p>The devil is in the details of how you &ldquo;go do some other work&rdquo; and &ldquo;every once in a while&rdquo; come back to check on your socket. Or, more likely, sockets plural: what kind of self-respecting program will only be dealing with a single socket?</p>

<p>The usual solution consists of two parts. First, redesign your program to be centered around an event loop, which continually cycles through the various things it might have to do—computation, reacting to user input, checking on and trying to read from any non-blocking sockets, processing the resulting data once it gets read, etc. Second, take advantage of some advanced APIs like <a href="http://linux.die.net/man/2/select">select(2)</a> or <a href="http://linux.die.net/man/4/epoll">epoll(4)</a>, to allow you to check on multiple sockets at once without needing to supply a buffer to each of them. In practice, the heavy lifting for both of these is usually provided by a library like <a href="http://libevent.org/">libevent</a> (the original) or <a href="https://github.com/libuv/libuv">libuv</a> (the new hotness).</p>

<h2 id="javascript-translation">JavaScript Translation</h2>

<p>In the previous episode, we were able to do a fairly direct translation of read(2)-in-a-threadpool into a promise-returning <code>file.readInto</code> API. For sockets, we&rsquo;re going to need to skip a few more steps: the jump from select(2) to evented programming is just too great to map out directly.</p>

<p>Let&rsquo;s assume we&rsquo;ve somehow integrated our host program&rsquo;s event loop (e.g., the one provided by libuv) with the JavaScript event loop. We can then have some host environment code that, each time through the loop, uses select(2) or similar to check if the socket has any data available. If it does, it needs to communicate that to JavaScript somehow. An easy way to do this would be with an event:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s2">&quot;readable&quot;</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="p">...</span> <span class="p">});</span>
</code></pre></div>
<p>Once we know that the socket has some data available, what should the JavaScript API for reading it look like? Its general shape will be pretty similar to our <code>file.readInto</code> from before. But this time, we know the result is going to be synchronous. That means we don&rsquo;t need to worry about observable data races, and so we can skip all the transfer stuff we had to do last time to avoid them. The end result ends up being:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">socket</span><span class="p">.</span><span class="nx">on</span><span class="p">(</span><span class="s2">&quot;readable&quot;</span><span class="p">,</span> <span class="p">()</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="kr">const</span> <span class="nx">bytesRead</span> <span class="o">=</span> <span class="nx">socket</span><span class="p">.</span><span class="nx">readInto</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">count</span><span class="p">);</span>
  <span class="c1">// `buffer`&#39;s bytes in the range (offset, offset + bytesRead) have been filled in</span>
<span class="p">});</span>
</code></pre></div>
<p>Not too bad!</p>

<h2 id="sockets-vs.-files">Sockets vs. Files</h2>

<p>With this JavaScript translation in hand, we can more easily probe the differences between non-blocking socket I/O, and file I/O. It turns out there are quite a few.</p>

<p>The first point to note is that we&rsquo;re being proactively told: <em>there is data ready for you</em>. But where does that data live while it&rsquo;s waiting for you to come pick it up? The answer is that the OS kernel maintains its own buffer of data for that socket, where the data accumulates until you read it. If you decline to read it, then the buffer will just keep filling up, until eventually it reaches a built-in limit. Once that happens, you&rsquo;ll start losing data!</p>

<p>This is a big difference between sockets and the higher-level stream APIs you might be used to. Streams generally go to great pains to ensure you never lose any data. But this means that any streams wrapping a socket must be careful to always pull data out of the kernel buffer before it gets too full, and then keep it around in their own user-space buffer until it&rsquo;s requested.</p>

<p>The second interesting difference is that we have much less control over how much data we&rsquo;re going to read. When the socket tells us that there&rsquo;s data available, it doesn&rsquo;t tell us how much. That means that in the above code, we can easily end up in a situation where <code>bytesRead &lt; count</code>: indeed, it will happen whenever the kernel buffer had fewer bytes available than we requested. This is in contrast with blocking file I/O, where the only time <code>bytesRead &lt; count</code> occurs is when we&rsquo;ve reached the end of the file.</p>

<p>Finally, I want to draw attention to the different way in which buffers are provided in the two scenarios. With files, since we are doing blocking I/O in a threadpool, we need to provide the buffer up front. Whereas with sockets, we can wait until the last minute to do so. This had a pretty drastic impact on the API surface when we tried to express the reuslt in JavaScript. In particular, while you could imagine a way to wrap up our JavaScript socket API into something like our JavaScript file API, you can&rsquo;t really do the other way around.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Reading from Files]]></title>
    <link href="https://blog.domenic.me/reading-from-files/"/>
    <updated>2015-03-05T09:00:00+09:00</updated>
    <id>https://blog.domenic.me/reading-from-files</id>
    <content type="html"><![CDATA[<p><em>This post is part of a series on the byte sources underlying the readable streams in the Streams Standard. See <a href="/byte-sources-introduction/">the introductory post</a> for more background and links to the rest of the series.</em></p>

<p>Once you have opened a file descriptor, you&rsquo;ll use the <a href="http://linux.die.net/man/2/read">read(2)</a> function to read bytes from it. In C the signature is</p>
<div class="highlight"><pre><code class="language-c" data-lang="c"><span class="kt">ssize_t</span> <span class="nf">read</span><span class="p">(</span><span class="kt">int</span> <span class="n">fd</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">buf</span><span class="p">,</span> <span class="kt">size_t</span> <span class="n">count</span><span class="p">);</span>
</code></pre></div>
<p>Translated into JavaScript this might look something like</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kr">const</span> <span class="nx">bytesRead</span> <span class="o">=</span> <span class="nx">file</span><span class="p">.</span><span class="nx">readInto</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">count</span><span class="p">);</span>
</code></pre></div>
<p>which will attempt to read <code>count</code> bytes into the <code>ArrayBuffer</code> <code>buffer</code>, starting at position <code>offset</code> into the <code>ArrayBuffer</code>. The returned number of bytes, <code>bytesRead</code>, might be less than the desired <code>count</code>, usually because you&rsquo;ve reached the end of the file.</p>

<p>The most interesting thing to note about read(2) is that it is blocking. So our above naive translation into JavaScript would actually lock up your browser or server for the amount of time the I/O happens. This is obviously a no-go if you&rsquo;re trying to write a server that serves more than one user in parallel, or trying to create a responsive 60 fps web page.</p>

<p>But of course we know how to fix this. We&rsquo;ll just turn it into a promise-returning function:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">file</span><span class="p">.</span><span class="nx">readInto</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">count</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">bytesRead</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="p">...</span> <span class="p">});</span>
</code></pre></div>
<p>Not so fast. How exactly do we plan on translating a blocking POSIX API into a non-blocking JavaScript API? The obvious answer is to use another thread. That is, off in a background thread, we pass the memory represented by <code>buffer</code> into read(2), and when read(2) finishes, we go back to the main thread and fulfill the promise we previously vended with read(2)&rsquo;s return value.</p>

<p>This solution has a major issue, however: <strong>data races</strong>. That is, it makes it possible to observe the memory in <code>buffer</code> changing out from under us, with code like the following:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kr">const</span> <span class="nx">view</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Uint8Array</span><span class="p">(</span><span class="nx">buffer</span><span class="p">);</span>
<span class="nx">file</span><span class="p">.</span><span class="nx">readInto</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">count</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">bytesRead</span> <span class="o">=&gt;</span> <span class="p">{</span> <span class="p">...</span> <span class="p">});</span>

<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">view</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">===</span> <span class="nx">view</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
</code></pre></div>
<p>Because the memory in <code>buffer</code> is being filled in by read(2) in the background thread, it&rsquo;s possible for this program to output <code>false</code>! Oh no!</p>

<p>In the io.js world, this is considered OK, and with some effort you can create situations like this using their native <code>Buffer</code> type. However, in the world of web browsers, and in general in any world where standards bodies need to get multiple vendors to agree, this is not going to fly. JavaScript&rsquo;s execution model is strongly based around a run-to-completion single-threaded paradigm, and if we poke holes in that by letting other threads modify our variables out from under us between two execution steps, all hell can break lose. No specs, libraries, or optimizing compilers are written to accomodate such a world.</p>

<p>One proposed solution would be to <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/ArrayBuffer/transfer"><em>transfer</em></a> the backing memory of the <code>ArrayBuffer</code> into a new <code>ArrayBuffer</code> that is only accessible once the read(2) call has finished. In code, that might look something like this:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">file</span><span class="p">.</span><span class="nx">readInto</span><span class="p">(</span><span class="nx">buffer</span><span class="p">,</span> <span class="nx">offset</span><span class="p">,</span> <span class="nx">count</span><span class="p">).</span><span class="nx">then</span><span class="p">(({</span> <span class="nx">result</span><span class="p">,</span> <span class="nx">bytesRead</span> <span class="p">})</span> <span class="o">=&gt;</span> <span class="p">{</span>
  <span class="c1">// `result` is backed by the same memory `buffer` used to be</span>
  <span class="c1">// backed by, but they are not equal:</span>
  <span class="nx">assert</span><span class="p">(</span><span class="nx">result</span> <span class="o">!==</span> <span class="nx">buffer</span><span class="p">);</span>
<span class="p">});</span>

<span class="c1">// `buffer`&#39;s backing memory has now been transferred, so trying to use</span>
<span class="c1">// `buffer` directly (or any views onto `buffer`) will throw:</span>
<span class="nx">assert</span><span class="p">.</span><span class="kr">throws</span><span class="p">(()</span> <span class="o">=&gt;</span> <span class="nx">buffer</span><span class="p">.</span><span class="nx">byteLength</span><span class="p">);</span>
<span class="nx">assert</span><span class="p">.</span><span class="kr">throws</span><span class="p">(()</span> <span class="o">=&gt;</span> <span class="k">new</span> <span class="nx">Uint8Array</span><span class="p">(</span><span class="nx">buffer</span><span class="p">));</span>
</code></pre></div>
<p>Note how once <code>buffer</code> has been transferred, the <code>buffer</code> instance itself is now useless: it is &ldquo;detached&rdquo; in spec terms.</p>

<p>We could also imagine other ways of avoiding the data races. For example, if we had an API that allowed the background thread to first detach, then &ldquo;reattach,&rdquo; the backing memory to <code>buffer</code>, we wouldn&rsquo;t need the separate <code>buffer</code> and <code>result</code> variables pointing to the same backing memory. Ideally such an API would allow us to detach and reattach <em>sections</em> of the <code>ArrayBuffer</code>, so that I could (for example) read multiple files in parallel into different sections of one large buffer. <a href="https://esdiscuss.org/topic/improving-detachment-for-array-buffers">I proposed this on es-discuss</a>, but nobody seemed to be interested.</p>

<p>Alternately, we could decide that for a low-level JavaScript API representing a file descriptor, data races are OK after all. In that case, <a href="https://blog.mozilla.org/javascript/2015/02/26/the-path-to-parallel-javascript/">Mozilla&rsquo;s <code>SharedArrayBuffer</code> proposal</a> would be a good fit—we&rsquo;ll just write to the shared array buffer in the background thread, while still allowing reading in the main thread. As mentioned before, it might be hard to get such a primitive past multiple vendors and into the relevant standards. But the desire to transpile threaded C and C++ code into asm.js is proving to be a powerful motivator, which might push it into acceptance.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Byte Sources: Introduction]]></title>
    <link href="https://blog.domenic.me/byte-sources-introduction/"/>
    <updated>2015-03-04T09:00:00+09:00</updated>
    <id>https://blog.domenic.me/byte-sources-introduction</id>
    <content type="html"><![CDATA[<p><em>This post is the beginning of a series of posts regarding some of the more interesting issues I&rsquo;ve encountered while working on the Streams Standard.</em></p>

<p>In the <a href="http://streams.spec.whatwg.org/">Streams Standard</a> we have the concept of readable streams, which are an abstraction on top of the lower-level <strong>underlying sources</strong>. In an abstract sense an underlying source is &ldquo;where the chunks of data come from.&rdquo; The most basic underlying sources are things like files or HTTP connections. (More complicated ones could be e.g. an underlying source that randomly generates data in-memory for test purposes, or one that synthesizes data from multiple concrete locations.) These basic underlying sources are concerned with direct production of bytes.</p>

<p>The major goal of the Streams Standard is to provide an efficient abstraction specifically for I/O. Thus, to design a suitable readable stream abstraction, we can&rsquo;t just think about general concepts of <a href="https://github.com/kriskowal/gtor/">reactivity</a> or <a href="https://github.com/zenparsing/async-iteration/">async iterables</a> or <a href="https://github.com/jhusain/asyncgenerator#introducing-observable">observables</a>. We need to dig deeper into how, exactly, the underlying sources will work. Otherwise we might find ourselves <a href="https://github.com/whatwg/streams/issues/253">scrambling</a> to reform the API at the last minute when confronted with real-world implementation challenges. (Oops.)</p>

<p>The current revision of the standard describes underlying sources as belonging to two broad categories: push sources, where data is constantly flowing in, and pull sources, where you specifically request it. The prototypal examples of these categories are TCP sockets and file descriptors. Once a TCP connection is open, the remote server will begin pushing data to you. Whereas, with a file, until you ask the OS to do a read, no I/O happens.</p>

<p>This division is conceptually helpful, but it&rsquo;s instructive to go deeper and look at the actual system APIs in play here. Given that concepts like &ldquo;events&rdquo; are way too high-level for an OS API, they end up being shaped quite differently than how you might imagine. We&rsquo;ll assume a POSIX environment for most of this series, but I&rsquo;d like to talk about some Windows specifics toward the end. Along the way we&rsquo;ll continually be trying to bridge the gap between these C APIs and how they might manifest in JavaScript, both to give the less-C-inclined readers a chance, and to illustrate the issues we&rsquo;ve been wrestling with in the Streams Standard.</p>

<p>So far these are the episodes I have planned:</p>

<ol>
<li>Byte sources: introduction (this post)</li>
<li><a href="/reading-from-files/">Reading from files</a></li>
<li><a href="/reading-from-sockets/">Reading from sockets</a></li>
<li>Byte source APIs on Windows</li>
<li>Byte source APIs in libuv and io.js</li>
<li>Readable streams</li>
</ol>

<p>I will update this post with links to them as they become available.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The Revealing Constructor Pattern]]></title>
    <link href="https://blog.domenic.me/the-revealing-constructor-pattern/"/>
    <updated>2014-02-14T09:00:00+09:00</updated>
    <id>https://blog.domenic.me/the-revealing-constructor-pattern</id>
    <content type="html"><![CDATA[<p>I want to document an interesting pattern we&rsquo;ve seen emerge in some recent web platform specs, including <a href="https://people.mozilla.org/%7Ejorendorff/es6-draft.html#sec-promise-objects">promises</a> and <a href="https://github.com/whatwg/streams">streams</a>. I&rsquo;m calling it the <strong>revealing constructor pattern</strong>.</p>

<h2 id="the-promises-example">The Promises Example</h2>

<p>Let&rsquo;s take the case of promises first, since that may be familiar. You can construct a new promise like so:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">var</span> <span class="nx">p</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Promise</span><span class="p">(</span><span class="kd">function</span> <span class="p">(</span><span class="nx">resolve</span><span class="p">,</span> <span class="nx">reject</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Use `resolve` to resolve `p`.</span>
    <span class="c1">// Use `reject` to reject `p`.</span>
<span class="p">});</span>
</code></pre></div>
<p>We see here that the <code>Promise</code> constructor takes a single function as its sole parameter (called the &ldquo;executor function&rdquo;). It then <em>immediately</em> calls that function with two arguments, <code>resolve</code> and <code>reject</code>. These arguments have the capability to manipulate the internal state of the newly-constructed <code>Promise</code> instance <code>p</code>.</p>

<p>I call this the revealing constructor pattern because the <code>Promise</code> constructor is <em>revealing</em> its internal capabilities, but only to the code that constructs the promise in question. The ability to resolve or reject the promise is only revealed to the constructing code, and is crucially <em>not</em> revealed to anyone <em>using</em> the promise. So if we hand off <code>p</code> to another consumer, say</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">doThingsWith</span><span class="p">(</span><span class="nx">p</span><span class="p">);</span>
</code></pre></div>
<p>then we can be sure that this consumer cannot mess with any of the internals that were revealed to us by the constructor. This is as opposed to, for example, putting <code>resolve</code> and <code>reject</code> methods on <code>p</code>, which anyone could call. (And no, adding underscores to the beginning of your method names won&rsquo;t save you.)</p>

<h2 id="historical-origins">Historical Origins</h2>

<p>The first place anyone can remember seeing this pattern is <a href="http://msdn.microsoft.com/en-us/library/windows/apps/br211866.aspx">in the WinJS promise implementation</a>. Before that, promise libraries used an awkward concept called a &ldquo;deferred.&rdquo; You would do something like this:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">var</span> <span class="nx">deferred</span> <span class="o">=</span> <span class="nx">Q</span><span class="p">.</span><span class="nx">defer</span><span class="p">();</span>
<span class="kd">var</span> <span class="nx">p</span> <span class="o">=</span> <span class="nx">deferred</span><span class="p">.</span><span class="nx">promise</span><span class="p">;</span>

<span class="c1">// Use `deferred.resolve` to resolve `p`.</span>
<span class="c1">// Use `deferred.reject` to reject `p`.</span>

<span class="nx">doThingsWith</span><span class="p">(</span><span class="nx">p</span><span class="p">);</span>
</code></pre></div>
<p>This was strange in a few ways, but most prominently, it was strange because you were constructing an object without using a constructor. This is generally an antipattern in JavaScript: we want to be able to clearly conceptualize the relationship between instances, constructor functions, and prototypes.</p>

<p>In contrast, with the revealing constructor pattern, we get our nice constructor invariants back. Things like:</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="nx">p</span> <span class="k">instanceof</span> <span class="nx">Promise</span><span class="p">;</span>
<span class="nx">p</span><span class="p">.</span><span class="nx">constructor</span> <span class="o">===</span> <span class="nx">Promise</span><span class="p">;</span>
<span class="nb">Object</span><span class="p">.</span><span class="nx">getPrototypeOf</span><span class="p">(</span><span class="nx">p</span><span class="p">)</span> <span class="o">===</span> <span class="nx">Promise</span><span class="p">.</span><span class="nx">prototype</span><span class="p">;</span>
</code></pre></div>
<p>These are all signs that you&rsquo;re dealing with a well-designed &ldquo;class&rdquo; in JavaScript, that will behave as you expect.</p>

<h2 id="the-streams-example">The Streams Example</h2>

<p>When putting together <a href="htwetps://github.com/whatwg/streams">the in-progress streams spec</a>, we of course drew a lot of inspiration from <a href="http://nodejs.org/api/stream.html">Node streams</a>. But Node streams do things kind of strangely, with regard to vending their capabilities.</p>

<p>To produce a Node stream representing a specific resource—which is somewhat analogous to producing a promise representing a specific asynchronous operation—you don&rsquo;t use the stream constructor. You don&rsquo;t even use something like the deferred pattern. Instead, you <em>subclass</em> the appropriate stream class. And then you overwrite certain underscore-prefixed methods!</p>

<p>So for a simplified example, here is how you would create a file reader stream using the Node APIs. I&rsquo;ll use ES6 class syntax for brevity, but that is just sugar over the usual ES5 incantations.</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kr">class</span> <span class="nx">FileReaderStream</span> <span class="kr">extends</span> <span class="nx">Readable</span> <span class="p">{</span>
  <span class="nx">constructor</span><span class="p">(</span><span class="nx">filename</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">this</span><span class="p">.</span><span class="nx">filename</span> <span class="o">=</span> <span class="nx">filename</span><span class="p">;</span>
  <span class="p">}</span>

  <span class="nx">_read</span><span class="p">(</span><span class="nx">size</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// Use `this.filename` to eventually call `this.push(chunk)`</span>
    <span class="c1">// with some data from the file, or `this.push(null)` to close</span>
    <span class="c1">// the stream, or `this.emit(&quot;error&quot;, e)` with an error.</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="kd">var</span> <span class="nx">myNodeStream</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">FileReaderStream</span><span class="p">(</span><span class="s2">&quot;/path/to/file.txt&quot;</span><span class="p">);</span>
</code></pre></div>
<p>There are two interesting actors here:</p>

<ul>
<li><code>_read</code>, a method not meant to be called by users directly, but instead called by the internals of the stream when it&rsquo;s time to read data from the underlying source.</li>
<li><code>push</code> and <code>emit(&quot;error&quot;, e)</code>, which have the capability to manipulate the stream&rsquo;s internal buffer and state machine. They too are not meant to be called by users directly, but instead only by implementers, inside their <code>_read</code> method (or perhaps inside the constructor).</li>
</ul>

<p>Interestingly, these are almost exactly analogous to the promise situation. <code>_read</code> is like the executor argment passed to the promise constructor, in that it consists of user code that does the actual work. And <code>push</code>/<code>emit</code> are capabilities, like <code>resolve</code>/<code>reject</code>, which can be used by the work-doing function to manipulate internal state.</p>

<p>In building the streams spec, we realized the Node pattern wasn&rsquo;t the way we wanted to go. Requiring subclassing for every stream instance is not ergonomic. Using underscore-prefixed methods as the extension point isn&rsquo;t realistic either. And letting any user access the capabilities involved is not tenable, in part because it means implementations can&rsquo;t build invariants around who has access to the internal buffer.</p>

<p>In contrast, the revealing constructor pattern works out really well. To create a file reader stream with whatwg/streams, you do something like</p>
<div class="highlight"><pre><code class="language-js" data-lang="js"><span class="kd">function</span> <span class="nx">createFileReaderStream</span><span class="p">(</span><span class="nx">filename</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="k">new</span> <span class="nx">ReadableStream</span><span class="p">({</span>
    <span class="nx">pull</span><span class="p">(</span><span class="nx">enqueue</span><span class="p">,</span> <span class="nx">close</span><span class="p">,</span> <span class="nx">error</span><span class="p">)</span> <span class="p">{</span>
      <span class="c1">// Use `filename` to eventually call `enqueue(chunk)`</span>
      <span class="c1">// with some data from the file, or `close()` to</span>
      <span class="c1">// close the stream, or `error(e)` with an error.</span>
    <span class="p">}</span>
  <span class="p">});</span>
<span class="p">}</span>

<span class="kd">var</span> <span class="nx">myWhatwgStream</span> <span class="o">=</span> <span class="nx">createFileReaderStream</span><span class="p">(</span><span class="s2">&quot;/path/to/file.txt&quot;</span><span class="p">);</span>
</code></pre></div>
<p>Notice the difference in the external API exposed. If you pass <code>myNodeStream</code> to another function, that function can mess with the stream&rsquo;s internal state as much as it wants, calling <code>push</code>, emitting <code>&quot;error&quot;</code> events, or even (despite the underscore) calling <code>_read</code>. Whereas if you pass <code>myWhatwgStream</code> around, consumers will not be able to do any of those things: the integrity of its internal state will be preserved.</p>

<p>(Plus, no subclassing!)</p>

<h2 id="when-would-i-use-this?">When Would I Use This?</h2>

<p>I admit that that the revealing constructor pattern seems a bit unorthodox. The number of actors involved—viz. the constructor itself, the work-doing function to which capabilities are given, and the capability arguments—can be hard to get your head around, at least the first few times you see them.</p>

<p>That said, it is a pretty elegant solution to a tricky problem. You might not need this level of encapsulation in your home-grown code. And even more widespread libraries may be able to skate by, as Node does, with documentation strategies and an attitude of &ldquo;don&rsquo;t do anything dumb with the capabilities we leave lying around, or it&rsquo;ll break.&rdquo; But when writing platform-level libraries and abstractions, which need to maintain their integrity in the face of any environment, the revealing constructor pattern really proves its worth.</p>

<p>And besides, patterns become part of our vernacular. Many patterns that are commonplace today seemed just as strange when they are introduced as the revealing constructor pattern might to you now. After working with promises and streams for a while, you might encounter a situation where a revealing constructor is a natural fit for your library&rsquo;s needs. Who knows!</p>

<h2 id="postscript">Postscript</h2>

<p>If those examples weren&rsquo;t enough, here&rsquo;s one that you should be able to connect with: <a href="https://gist.github.com/domenic/9003334">an event emitter using the revealing constructor pattern</a>. This is an evolution of some of my <a href="https://github.com/domenic/pubit">earlier work</a> on event emitters with separate capabilities.</p>
]]></content>
  </entry>
  
</feed>
